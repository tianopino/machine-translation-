{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from pickle import load\n",
    "from pickle import dump\n",
    "from numpy import array\n",
    "from numpy.random import shuffle\n",
    "from numpy import argmax\n",
    "\n",
    "# import Keras functions\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from attention import Attention\n",
    "\n",
    "# import BLEU calculator from NLTK\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "with open('pol.txt', 'r', encoding='utf-8') as f:\n",
    "    pol_dataset = f.read()\n",
    "    \n",
    "# lower\n",
    "pol_dataset = pol_dataset.lower()\n",
    "\n",
    "# Split samples\n",
    "pol_lines = pol_dataset.strip().split('\\n')\n",
    "pol_data = [i.split('\\t')[:2] for i in pol_lines]\n",
    "\n",
    "# Remove punctuation\n",
    "def remove_punct(sentence):\n",
    "    for punct in string.punctuation:\n",
    "        sentence = sentence.replace(punct, '')\n",
    "    return sentence\n",
    "    \n",
    "for i in pol_data:\n",
    "    i[0] = remove_punct(i[0])\n",
    "    i[1] = remove_punct(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "shuffle(pol_data)\n",
    "pol_splitpoint = len(pol_data) // 10\n",
    "pol_train_data = pol_data[:-pol_splitpoint]\n",
    "pol_test_data = pol_data[-pol_splitpoint:]\n",
    "\n",
    "# Save data\n",
    "dump(pol_data, open('pol_data.txt', 'wb'))\n",
    "dump(pol_train_data, open('pol_train_data.txt', 'wb'))\n",
    "dump(pol_test_data, open('pol_test_data.txt', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train eng2pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "pol_data = load(open('pol_data.txt', 'rb'))\n",
    "pol_train_data = load(open('pol_train_data.txt', 'rb'))\n",
    "pol_test_data = load(open('pol_test_data.txt', 'rb'))\n",
    "\n",
    "pol_data = array(pol_data)\n",
    "pol_train_data = array(pol_train_data)\n",
    "pol_test_data = array(pol_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "eng_tokenizer = Tokenizer()\n",
    "eng_tokenizer.fit_on_texts(pol_data[:, 0])\n",
    "\n",
    "pol_tokenizer = Tokenizer()\n",
    "pol_tokenizer.fit_on_texts(pol_data[:, 1])\n",
    "\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "pol_vocab_size = len(pol_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(max(len(i.split()) for i in pol_data[:, 0]))\n",
    "print(max(len(i.split()) for i in pol_data[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sentence length\n",
    "eng_length = 10\n",
    "pol_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "trainX = eng_tokenizer.texts_to_sequences(pol_train_data[:, 0])\n",
    "trainX = pad_sequences(trainX, maxlen= eng_length, padding='post')\n",
    "\n",
    "testX = eng_tokenizer.texts_to_sequences(pol_test_data[:, 0])\n",
    "testX = pad_sequences(testX, maxlen= eng_length, padding='post')\n",
    "\n",
    "trainY = pol_tokenizer.texts_to_sequences(pol_train_data[:, 1])\n",
    "trainY = pad_sequences(trainY, maxlen= pol_length, padding='post')\n",
    "\n",
    "testY = pol_tokenizer.texts_to_sequences(pol_test_data[:, 1])\n",
    "testY = pad_sequences(testY, maxlen= pol_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 10, 200)      1702600     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 10, 256)      253440      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "last_hidden_state (Lambda)      (None, 256)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_score_vec (Dense)     (None, 10, 256)      65536       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_score (Dot)           (None, 10)           0           last_hidden_state[0][0]          \n",
      "                                                                 attention_score_vec[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attention_weight (Activation)   (None, 10)           0           attention_score[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "context_vector (Dot)            (None, 256)          0           bidirectional[0][0]              \n",
      "                                                                 attention_weight[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_output (Concatenate)  (None, 512)          0           context_vector[0][0]             \n",
      "                                                                 last_hidden_state[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "attention_vector (Dense)        (None, 128)          65536       attention_output[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)  (None, 10, 128)      0           attention_vector[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 10, 256)      198144      repeat_vector_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 10, 21560)    5540920     bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 7,826,176\n",
      "Trainable params: 7,826,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# define the encoder-decoder model\n",
    "n_units = 64\n",
    "embedding_size = 200\n",
    "\n",
    "# encoder\n",
    "eng_input = Input(shape=(eng_length,), dtype='float32')\n",
    "embedding = Embedding(eng_vocab_size, embedding_size, input_length=eng_length)(eng_input)\n",
    "encoder_gru = Bidirectional(GRU(n_units*2, return_sequences=True, dropout=0.2))(embedding)\n",
    "encoder_att = Attention()(encoder_gru)\n",
    "# decoder\n",
    "repeat = RepeatVector(pol_length)(encoder_att)\n",
    "decoder_gru = Bidirectional(GRU(n_units*2, return_sequences=True, dropout=0.2))(repeat)\n",
    "pol_output = TimeDistributed(Dense(pol_vocab_size, activation='softmax'))(decoder_gru)\n",
    "model = Model(eng_input, pol_output)\n",
    "\n",
    "# create a german to english translation model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# summarise the model\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 10, 200)           1702600   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 64)                51072     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 10, 64)            24960     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 10, 21560)         1401400   \n",
      "=================================================================\n",
      "Total params: 3,180,032\n",
      "Trainable params: 3,180,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# define the encoder-decoder model\n",
    "n_units = 64\n",
    "embedding_size = 200\n",
    "\n",
    "# encoder\n",
    "eng_input = Input(shape=(eng_length, ), dtype='float32')\n",
    "embedding = Embedding(eng_vocab_size, embedding_size, input_length=eng_length)(eng_input)\n",
    "encoder_gru = GRU(n_units, dropout=0.2)(embedding)\n",
    "# encoder_att = Attention()(encoder_gru)\n",
    "# decoder\n",
    "repeat = RepeatVector(pol_length)(encoder_gru)\n",
    "decoder_gru = GRU(n_units, return_sequences=True, dropout=0.2)(repeat)\n",
    "pol_output = TimeDistributed(Dense(pol_vocab_size, activation='softmax'))(decoder_gru)\n",
    "model = Model(eng_input, pol_output)\n",
    "\n",
    "# create a german to english translation model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# summarise the model\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "73/73 - 169s - loss: 5.4814 - val_loss: 4.4007\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.40069, saving model to model.h5\n",
      "Epoch 2/5\n",
      "73/73 - 165s - loss: 4.2841 - val_loss: 4.2935\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.40069 to 4.29346, saving model to model.h5\n",
      "Epoch 3/5\n",
      "73/73 - 165s - loss: 4.1392 - val_loss: 4.1844\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.29346 to 4.18443, saving model to model.h5\n",
      "Epoch 4/5\n",
      "73/73 - 166s - loss: 4.0568 - val_loss: 4.1468\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.18443 to 4.14678, saving model to model.h5\n",
      "Epoch 5/5\n",
      "73/73 - 165s - loss: 4.0191 - val_loss: 4.1249\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.14678 to 4.12490, saving model to model.h5\n"
     ]
    }
   ],
   "source": [
    "# because training takes time, we checkpoint the model during training\n",
    "# this saves the partially trained model any time that the validation loss is reduced\n",
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "history = model.fit(trainX, trainY, epochs = 5, batch_size = 512, validation_data = (testX, testY), callbacks = [checkpoint], verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17b4d7780>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the history dictionary \n",
    "hist=history.history\n",
    "epochs=range(1,len(hist['loss'])+1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot loss curves\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epochs,hist['loss'],'bo',label=\"Training loss\")\n",
    "plt.plot(epochs,hist['val_loss'],'r-',label=\"Validation loss\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src=[myanmar is ruled by a military dictatorship], target=[w myanmarze rządzi dyktatura wojskowa], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "src=[tom took the day off], target=[tom wziął dzień wolnego], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "src=[i promise you ill look after you], target=[przyrzekam że będę się tobą opiekował], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "src=[they have time to spend with their families or to enjoy their hobbies], target=[mają czas żeby spędzać go z rodzinami albo uprawiać swoje hobby], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "src=[where can i park my car], target=[gdzie mogę zaparkować samochód], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "src=[he should arrive at the airport by 9 am], target=[powinien dotrzeć na lotnisko przed 900], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "src=[the party doesnt start for another hour], target=[impreza zaczyna się dopiero za godzinę], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "src=[i plan on going there], target=[planuję tam pojechać], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "src=[a mortgage is a kind of loan that people can use to buy a house], target=[hipoteka to rodzaj kredytu który ludzie mogą wykorzystać do kupna domu], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "src=[you shouldnt forget that], target=[nie powinieneś o tym zapominać], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-d44e8766aa97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BLEU-1: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BLEU-2: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BLEU-3: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mcorpus_bleu\u001b[0;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# denominator for the corpus-level modified precision.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mp_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0mp_numerators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mp_denominators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mmodified_precision\u001b[0;34m(references, hypothesis, n)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mreference\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         reference_counts = (\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         )\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                     \u001b[0mself_get\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# evaluate the performance of the model\n",
    "actual = []\n",
    "predicted = []\n",
    "for i, sample in enumerate(testX):\n",
    "    sample = sample.reshape((1, sample.shape[0]))\n",
    "    prediction = model.predict(sample, verbose=0)[0]\n",
    "    integers = [argmax(vector) for vector in prediction]\n",
    "    target = []\n",
    "    for j in integers:\n",
    "        for w, index in pol_tokenizer.word_index.items():\n",
    "            word = w if index == j else None\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    translation = ' '.join(target)\n",
    "    \n",
    "    if i < 10:\n",
    "        print('src=[%s], target=[%s], predicted=[%s]' % (pol_test_data[i][0], pol_test_data[i][1], translation))\n",
    "        \n",
    "    actual.append([pol_test_data[i][1].split()])\n",
    "    predicted.append(translation.split())\n",
    "    \n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
